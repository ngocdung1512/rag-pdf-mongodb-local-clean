CÃ‚U Lá»†NH DÃ™NG Äá»‚ CHáº Y: & "C:\Users\ADMIN\anaconda3\envs\mongodb\Scripts\streamlit.exe" run chatbot-app.py


# ğŸ§  Chat vá»›i PDF báº±ng MongoDB Vector Store

á»¨ng dá»¥ng cho phÃ©p ngÆ°á»i dÃ¹ng:
- Upload file PDF.
- TrÃ­ch xuáº¥t vÃ  xá»­ lÃ½ ná»™i dung â†’ embeddings.
- LÆ°u embeddings vÃ o MongoDB vá»›i metadata.
- Äáº·t cÃ¢u há»i vÃ  nháº­n cÃ¢u tráº£ lá»i dá»±a trÃªn PDF Ä‘Ã£ lÆ°u.

---

## ğŸ” 1. Cáº¥u hÃ¬nh MongoDB

```python
ATLAS_URI = getenv("ATLAS_URI")
MONGODB_DB = getenv("MONGODB_DB")
MONGODB_COLLECTION = getenv("MONGODB_COLLECTION")
client = MongoClient(ATLAS_URI, server_api=ServerApi('1'))
```

---

## âœ… 2. Kiá»ƒm tra káº¿t ná»‘i MongoDB

```python
def test_mongodb_connection():
    client.admin.command('ping')
```

---

## ğŸ§  3. Cáº¥u hÃ¬nh Cache cho LLM

```python
set_llm_cache(MongoDBCache(...))
```

---

## ğŸ“„ 4. Xá»­ lÃ½ PDF

```python
def get_pdf_text(uploaded_files)
def get_text_chunks(text)
```

---

## ğŸ§  5. LÆ°u embeddings vÃ o MongoDB

```python
def get_vectorstore(text_chunks, source_name):
    metadatas = [{"source": source_name} for _ in text_chunks]
    vector_search.add_texts([chunk], [metadata])
```

---

## ğŸ”„ 6. Táº£i láº¡i vectorstore (khÃ´ng cáº§n reprocess)

```python
def load_vectorstore():
    return MongoDBAtlasVectorSearch(...)
```

---

## ğŸ’¬ 7. Truy váº¥n vá»›i LLM Chain

```python
def get_conversation_chain(vectorstore):
    retriever = vectorstore.as_retriever(...)
    return ConversationalRetrievalChain(...)
```

---

## ğŸ–¥ï¸ 8. HÃ m main()

- Upload file
- Process file â†’ vector â†’ lÆ°u MongoDB
- Gá»i láº¡i `get_conversation_chain`

---

## âœ… Tá»•ng káº¿t luá»“ng xá»­ lÃ½

| Giai Ä‘oáº¡n | TÃ¡c vá»¥ |
|----------|--------|
| Upload | NgÆ°á»i dÃ¹ng chá»n file PDF |
| Process | TrÃ­ch xuáº¥t â†’ chunk â†’ embed â†’ lÆ°u |
| Query | Há»i â†’ tÃ¬m Ä‘oáº¡n phÃ¹ há»£p â†’ tráº£ lá»i |
| Reuse | KhÃ´ng cáº§n upload láº¡i sau nÃ y |

---

